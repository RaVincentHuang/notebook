## æ”¶é›†
[DeepGraphLibrary](https://www.dgl.ai/)

## ç†è®º

### Spatial-based
[[Graph Attention Networks (GAT)]]
[[GIN (Graph Isomorphism Network)]]

### Spectral-based
[[Spectral Graph Theory]]
[[Graph Convolutional Networks (GCN)]]

## å®šä¹‰
$$
G = (V, \mathbf{A}, \mathbf{X})
$$
$A$ is the adjacency matrix (assume binary)
$\mathbf{X} \in \mathbb{R}^{|V|\times m}$ is a matrix of node features

### å›¾çš„æ€§è´¨

[[Permutation invariant]]
Graph does not have a canonical order of the nodes.
Graph neural networks consist of multiple permutation equivariant / invariant functions.
## GNN Layer
*GNN Layer = Message + Aggregation*
### Message computation
**Message function** 
$$
m_u^{(l)} = \mathrm{MSG}^{(l)}(h_u^{(l - 1)})
$$
*example* Linear
$$
m_u^{(l)} = W^{(l)}h_u^{(l - 1)}
$$
### Message Aggregation
$$
h_v^{(l)} = \mathrm{AGG}^{(l)}\left(\{m_u^{(l)}\mid u \in N(v)\right)
$$
ä¾‹å¦‚ï¼š$\mathrm{sum}(\cdot)$ã€$\mathrm{mean}(\cdot)$ã€$\mathrm{max}(\cdot)$
**Issue** Information from node $ğ‘£$ itself could get lost
ä¿®æ”¹**Aggregation**ç¯èŠ‚
$$
h_v^{(l)} = \mathrm{concat}\left(\mathrm{AGG}^{(l)}(\{m_u^{(l)}\mid u \in N(v)), m_v^{(l)}\right)
$$
### Nonlinearity (activation)
$\sigma(\cdot)$ä¾‹å¦‚$\mathrm{ReLU}(\cdot),\mathrm{sigmoid}(\cdot)$

### ä¾‹å­
#### [[Graph Convolutional Networks (GCN)]] 
$$
\begin{align} 
h_v^{(k + 1)} &= \sigma\left(W_k\sum_{u \in N(v)}\frac{h_u^{(k)}}{|N(v)|} + B_kh_v^{(k)}\right) \\
 &= \sigma\left(\sum_{u \in N(v)}W_k\frac{h_u^{(k)}}{|N(v)|} + B_kh_v^{(k)}\right)
\end{align}
$$
**Message**
$$
m_u^{(l)}=\frac{1}{|N(v)|}W^{(l)}h_u^{(l - 1)}
$$
**Aggregation**
$$
h_v^{(l)} = \sigma(\mathrm{sum}\left(\{m_u^{(l)}\mid u \in N(v)\}\right))
$$
#### [[GraphSAGE]]
$$
\begin{align} 
h_v^{(l)}  &= \sigma\left(W^{(l)}\cdot\mathrm{concat}(h_v^{(l-1)},\mathrm{AGG}(\{h_u^{(l-1)}\mid \forall u \in N(v\}))\right) \\
 &= \sigma\left(\mathrm{concat}(W^{(l)} h_v^{(l-1)},\mathrm{AGG}(\{ W^{(l)}h_u^{(l-1)}\mid \forall u \in N(v\}))\right)
\end{align}
$$
**Message**
$$
m_u^{(l)}=W^{(l)}h_u^{(l - 1)}
$$
**Aggregation**
$$
h_v^{(l)} = \sigma(\mathrm{concat}(m_v^{(l)},\mathrm{AGG}(\{ m_u^{(l)}\mid \forall u \in N(v\})))
$$
#### [[Graph Attention Networks (GAT)]]

### Layer in Practice
#### Linear
#### BatchNorm
ä½¿ä¸€æ‰¹æ•°æ®çš„å‡å€¼åœ¨0ï¼Œæ–¹å·®ä¸º1
#### Dropout
#### Actiation
#### Attention
#### Aggregation
