## 早期尝试

**LeNet**

## 突破进展

**AlexNet**
	Dropout
	Relu
	分组

## 加深

**VGGNet**
## 分组卷积
**Inception**
## ResNet
_梯度消失_
## 大核
**ConvNet**, **RepLKNet**

## 轻量化

目标
+ 效果好精度高
+ 可学习，好训练
+ 精简——参数计算量小
+ 好迁移（VGG > moblieNet）

方向（深/宽）【感受野放大】
+ 参数多——过拟合
+ 梯度爆炸，梯度消失

*NAS（Network Arch Search）*

方法
+ 结构化方法：分组卷积，残差结构
+ 创新提取方式：特殊卷积，提取操作，训练方法
+ 正则化、注意力机制

## 普通卷积

## Group Convolution
沿通道拆 -->通道内部做卷积

## Depthwise Convolution
g = k = C的分组卷积
仅提取空间信息

## Pointwise Convolution
$1 \times 1 \times k$的卷积
仅提取通道信息

**Network in Network**
**SqueezeNet**

多通道使得特征更稀疏

## 通道分离卷积
